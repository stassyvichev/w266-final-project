{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5270, 5)\n"
     ]
    }
   ],
   "source": [
    "# LOAD THE DATA\n",
    "filename = \"data/Labeled_Colorado_Flu_Study_Tweets_AvI_RvN_SvO.csv\"\n",
    "coloradoData = pd.read_csv(filename, sep=\"\\t\")\n",
    "print(coloradoData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Content</th>\n",
       "      <th>Related_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>don't worry it's not swine flu, i already got ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muh. if i am getting sick and it's not swine f...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is up with my boy?  this morning i though...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>getting better,no more piggy flu 4 me,it was n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@robbsterr yay for man txting you.. in other n...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Tweet_Content  Related_Label\n",
       "0  don't worry it's not swine flu, i already got ...            NaN\n",
       "1  muh. if i am getting sick and it's not swine f...            1.0\n",
       "2  what is up with my boy?  this morning i though...            NaN\n",
       "3  getting better,no more piggy flu 4 me,it was n...            1.0\n",
       "4  @robbsterr yay for man txting you.. in other n...            0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coloradoData[['Tweet_Content', 'Related_Label']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4413, 5)\n",
      "(4413,)\n",
      "(4413,)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "# get all data with labels present for the column we care about (Related/NotRelated)\n",
    "coloradoVal = coloradoData.dropna(subset=[\"Related_Label\"])\n",
    "print(coloradoVal.shape)\n",
    "\n",
    "# extract X and Y as np arrays, so that we can feed them to tensors. \n",
    "X = coloradoVal[\"Tweet_Content\"]\n",
    "Y = coloradoVal[\"Related_Label\"]\n",
    "print(X.values.shape)\n",
    "print(Y.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Tweet_Content</th>\n",
       "      <th>Awareness_Label</th>\n",
       "      <th>Related_Label</th>\n",
       "      <th>Self_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5222838706</td>\n",
       "      <td>muh. if i am getting sick and it's not swine f...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5918860304</td>\n",
       "      <td>getting better,no more piggy flu 4 me,it was n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4631607800</td>\n",
       "      <td>@robbsterr yay for man txting you.. in other n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6004314210</td>\n",
       "      <td>swine flu has arrived at my daughter's kinderg...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5225053106</td>\n",
       "      <td>i think im getting flu soon.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet_ID                                      Tweet_Content  \\\n",
       "1  5222838706  muh. if i am getting sick and it's not swine f...   \n",
       "3  5918860304  getting better,no more piggy flu 4 me,it was n...   \n",
       "4  4631607800  @robbsterr yay for man txting you.. in other n...   \n",
       "5  6004314210  swine flu has arrived at my daughter's kinderg...   \n",
       "6  5225053106                       i think im getting flu soon.   \n",
       "\n",
       "   Awareness_Label  Related_Label  Self_Label  \n",
       "1              0.0            1.0         1.0  \n",
       "3              0.0            1.0         1.0  \n",
       "4              0.0            0.0         1.0  \n",
       "5              0.0            1.0         0.0  \n",
       "6              0.0            1.0         1.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coloradoVal.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "training label shape: (3530,)\n",
      "test label shape: (441,)\n",
      "dev label shape: (442,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test, dev (80%,10%,10%) (3530, 441, 442 each)\n",
    "np.random.seed(42)\n",
    "# train_data, train_labels = X[:3530], Y[:3530]\n",
    "# test_data, test_labels = X[3530:3971], Y[3530:3971]\n",
    "# dev_data, dev_labels = X[3971:], Y[3971:]\n",
    "\n",
    "train, test, dev = np.split(X.sample(frac=1), [int(.8*len(X)), int(.9*len(X))])\n",
    "\n",
    "train_y = Y[train.index]\n",
    "test_y = Y[test.index]\n",
    "dev_y = Y[dev.index]\n",
    "\n",
    "# convert to numpy arrays\n",
    "train_data, test_data, dev_data, train_labels, test_labels, dev_labels = \\\n",
    "    train.values, test.values, dev.values, \\\n",
    "    train_y.values, test_y.values, dev_y.values \n",
    "train_labels = train_labels.astype(int)\n",
    "test_labels = test_labels.astype(int)\n",
    "dev_labels = dev_labels.astype(int)\n",
    "\n",
    "print(type(train_data))\n",
    "print 'training label shape:', train_labels.shape\n",
    "print 'test label shape:', test_labels.shape\n",
    "print 'dev label shape:', dev_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'who is getting their flu shot for the first time! just did it, man am i dizzy',\n",
       "       \"my arm is sooo soar after the swine flu shot!!! it hurts... but i'm getting used to pain because i'm in a lot of pain a lot... soo......\",\n",
       "       \"got my seasonal flu shot today, even though i'm a big scaredy cat who is afraid of needles.\",\n",
       "       ...,\n",
       "       'good thing were not worried about swine flu. its a great time to be playing beer pong --jimmy fallon',\n",
       "       \"think i'm getting the stomach flu my mom had..ugh!\",\n",
       "       'finally getting over the flu ... wow this one was wild!  i am counting on a sick free remainder of the year!'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimized parameter settings for logistic regression and Multinomial Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression C : {'C': 0.1} best score:  0.749008498584\n",
      "Best multinomial bayes alpha:  {'alpha': 0.5} best score:  0.750991501416\n"
     ]
    }
   ],
   "source": [
    "# Find the best parameters using CountVectorizer\n",
    "cv = CountVectorizer(analyzer='word')\n",
    "cvtrain = cv.fit_transform(train_data)\n",
    "# print(train.shape) # [samples, features] (3530, 8553)\n",
    "\n",
    "# Find the best parameters for C in logistic regression\n",
    "logit = LogisticRegression() # default penalty='l2'\n",
    "clist = {'C': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0, 2.0, 10.0]}\n",
    "lr = GridSearchCV(logit,clist)\n",
    "lr.fit(cvtrain, train_labels)\n",
    "print \"Best logistic regression C :\", lr.best_params_, \"best score: \",lr.best_score_\n",
    "\n",
    "# for c in clist['C']:\n",
    "#     logit2=LogisticRegression(C=c)\n",
    "#     logit2.fit(cvtrain, train_labels)\n",
    "#     weight=[]\n",
    "#     for x in range(len(logit2.coef_)):\n",
    "#         weight.append(sum(logit2.coef_[x]**2))\n",
    "#     print \"C=\", c, \", sum of squared weight values:\", weight\n",
    "    \n",
    "# Find the best parameters for alpha in Multinomial Bayes\n",
    "mb = MultinomialNB()\n",
    "alphas = {'alpha': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0, 2.0, 10.0]}        \n",
    "mnb= GridSearchCV(mb, alphas)\n",
    "mnb.fit(cvtrain, train_labels)\n",
    "print \"Best multinomial bayes alpha: \", mnb.best_params_,\"best score: \", mnb.best_score_\n",
    "\n",
    "# for a in alphas['alpha']:\n",
    "#     mb2=MultinomialNB(alpha=a)\n",
    "#     mb2.fit(cvtrain, train_labels)\n",
    "#     weight=[]\n",
    "#     for x in range(len(mb2.coef_)):\n",
    "#         weight.append(sum(mb2.coef_[x]**2))\n",
    "#     print \"alpha=\", a, \", sum of squared weight values:\", weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression C : {'C': 0.5} best score:  0.747875354108\n",
      "Best multinomial bayes alpha:  {'alpha': 0.3} best score:  0.738526912181\n"
     ]
    }
   ],
   "source": [
    "# Find the best parameters using TfidfVectorizer\n",
    "tf= TfidfVectorizer(analyzer='word')\n",
    "tftrain=tf.fit_transform(train_data)\n",
    "\n",
    "# Find the best parameters for C in logistic regression\n",
    "logit = LogisticRegression() # default penalty='l2'\n",
    "clist = {'C': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0, 2.0, 10.0]}\n",
    "lr = GridSearchCV(logit,clist)\n",
    "lr.fit(tftrain, train_labels)\n",
    "print \"Best logistic regression C :\", lr.best_params_, \"best score: \",lr.best_score_\n",
    "\n",
    "# for c in clist['C']:\n",
    "#     logit2=LogisticRegression(C=c)\n",
    "#     logit2.fit(train, train_labels)\n",
    "#     weight=[]\n",
    "#     for x in range(len(logit2.coef_)):\n",
    "#         weight.append(sum(logit2.coef_[x]**2))\n",
    "#     print \"C=\", c, \", sum of squared weight values:\", weight\n",
    "    \n",
    "# Find the best parameters for alpha in Multinomial Bayes\n",
    "mb = MultinomialNB()\n",
    "alphas = {'alpha': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0, 2.0, 10.0]}        \n",
    "mnb= GridSearchCV(mb, alphas)\n",
    "mnb.fit(tftrain, train_labels)\n",
    "print \"Best multinomial bayes alpha: \", mnb.best_params_,\"best score: \", mnb.best_score_\n",
    "\n",
    "# for a in alphas['alpha']:\n",
    "#     mb2=MultinomialNB(alpha=a)\n",
    "#     mb2.fit(tftrain, train_labels)\n",
    "#     weight=[]\n",
    "#     for x in range(len(mb2.coef_)):\n",
    "#         weight.append(sum(mb2.coef_[x]**2))\n",
    "#     print \"alpha=\", a, \", sum of squared weight values:\", weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size without preprocessing:  8553\n",
      "F1 score without preprocessing:  0.739819004525\n",
      "Dictionary size with preprocessing:  8487\n",
      "F1 score with preprocessing:  0.733031674208\n",
      "Dictionary size reduction:  66\n"
     ]
    }
   ],
   "source": [
    "def better_preprocessor(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub('^[^a-zA-z]*|[^a-zA-Z]*$','',s)\n",
    "    s = re.sub('\\s+', ' ', s).strip() \n",
    "    s = re.sub(r'\\b\\d+\\b', '', s)\n",
    "    s = re.sub(r'<.*?>', '', s)\n",
    "    s = re.sub(r\"\\\\\", \"\", s)    \n",
    "    s = re.sub(r\"\\'\", \"\", s)    \n",
    "    s = re.sub(r\"\\\"\", \"\", s) \n",
    "    return s\n",
    "# TO DO: add specific twitter preprocessor\n",
    "# https://marcobonzanini.com/2015/03/09/mining-twitter-data-with-python-part-2/\n",
    "\n",
    "def preprocess():\n",
    "    # no processing\n",
    "    vect = CountVectorizer(preprocessor=None) # set preprocessor to default none\n",
    "    cvdata=vect.fit_transform(train_data)\n",
    "    logit = LogisticRegression() # default penalty='l2'\n",
    "    logit.fit(cvdata, train_labels)\n",
    "    \n",
    "    dev=vect.transform(dev_data)\n",
    "    pred = logit.predict(dev)\n",
    "    score = metrics.f1_score(dev_labels, pred, average='micro')\n",
    "    print \"Dictionary size without preprocessing: \", len(vect.vocabulary_) # without preprocessing\n",
    "    print \"F1 score without preprocessing: \", score\n",
    "    \n",
    "    # preprocessing\n",
    "    cv = CountVectorizer(preprocessor=better_preprocessor)\n",
    "    cvdata2=cv.fit_transform(train_data)\n",
    "    logit2 = LogisticRegression() # default penalty='l2'\n",
    "    logit2.fit(cvdata2, train_labels)\n",
    "    \n",
    "    dev2=cv.transform(dev_data)\n",
    "    pred2 = logit2.predict(dev2)\n",
    "    score2 = metrics.f1_score(dev_labels, pred2, average='micro')\n",
    "    print \"Dictionary size with preprocessing: \", len(cv.vocabulary_)\n",
    "    print \"F1 score with preprocessing: \", score2\n",
    "    print \"Dictionary size reduction: \", len(vect.vocabulary_)-len(cv.vocabulary_)\n",
    "\n",
    "\n",
    "preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Variations of Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev data processed accuracy: 0.748868778281\n",
      "Dev data processed entropy loss: 0.566095281728\n",
      "Test data processed accuracy: 0.702947845805\n",
      "Test data processed entropy loss: 0.596831628413\n"
     ]
    }
   ],
   "source": [
    "def cv_log(param, data, labels, processor=None):\n",
    "\n",
    "    cv= CountVectorizer(analyzer='word', preprocessor=processor)\n",
    "    cvdata=tf.fit_transform(train_data)\n",
    "    logit1 = LogisticRegression(C=param)\n",
    "    logit1.fit(cvdata, train_labels)\n",
    "    \n",
    "    cvdev=tf.transform(data)\n",
    "    \n",
    "    # predict classification\n",
    "    predict= logit1.predict(cvdev)\n",
    "    post_prob = logit1.predict_proba(cvdev)\n",
    "    \n",
    "    accuracy=metrics.f1_score(labels, predict, average='micro')\n",
    "    loss=metrics.log_loss(labels, post_prob)\n",
    "    \n",
    "    return [accuracy, loss]\n",
    "\n",
    "# ## STUDENT END ###\n",
    "\n",
    "# print'Dev data accuracy:', cv_log(0.1, dev_data, dev_labels)[0]\n",
    "print'Dev data processed accuracy:', cv_log(0.1, dev_data, dev_labels, better_preprocessor)[0]\n",
    "\n",
    "# print'Dev entropy loss:', cv_log(0.1, dev_data, dev_labels)[1]\n",
    "print'Dev data processed entropy loss:', cv_log(0.1, dev_data, dev_labels, better_preprocessor)[1]\n",
    "\n",
    "# print'Test data accuracy:', cv_log(0.1, test_data, test_labels)[0]\n",
    "print'Test data processed accuracy:', cv_log(0.1, test_data, test_labels,better_preprocessor)[0]\n",
    "\n",
    "# print'Test entropy loss:', cv_log(0.1, test_data, test_labels)[1]\n",
    "print'Test data processed entropy loss:', cv_log(0.1, test_data, test_labels,better_preprocessor)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev data processed accuracy: 0.755656108597\n",
      "Dev data processed entropy loss: 0.509039494116\n",
      "test data processed accuracy: 0.721088435374\n",
      "Test data processed entropy loss: 0.5537123254\n"
     ]
    }
   ],
   "source": [
    "def tfid_log(param, data, labels, processor=None):\n",
    "\n",
    "    tf= TfidfVectorizer(analyzer='word', preprocessor=processor)\n",
    "    tfdata=tf.fit_transform(train_data)\n",
    "    logit = LogisticRegression(C=param)\n",
    "    logit.fit(tfdata, train_labels)\n",
    "    \n",
    "    tfdev=tf.transform(data)\n",
    "    \n",
    "    # predict classification\n",
    "    predict= logit.predict(tfdev)\n",
    "    post_prob = logit.predict_proba(tfdev)\n",
    "    \n",
    "    accuracy=metrics.f1_score(labels, predict, average='micro')\n",
    "    loss=metrics.log_loss(labels, post_prob)\n",
    "    return [accuracy, loss]\n",
    "\n",
    "\n",
    "# print'dev data accuracy:', tfid_log(0.5, dev_data, dev_labels)[0]\n",
    "print'dev data processed accuracy:', tfid_log(0.5, dev_data, dev_labels, better_preprocessor)[0]\n",
    "\n",
    "# print'Dev entropy loss:', tfid_log(0.5, dev_data, dev_labels)[1]\n",
    "print'Dev data processed entropy loss:', tfid_log(0.5, dev_data, dev_labels, better_preprocessor)[1]\n",
    "\n",
    "# print'test data accuracy:', tfid_log(0.5, test_data, test_labels)[0]\n",
    "print'test data processed accuracy:', tfid_log(0.5, test_data, test_labels, better_preprocessor)[0]\n",
    "\n",
    "# print'Test entropy loss:', tfid_log(0.5, test_data, test_labels)[1]\n",
    "print'Test data processed entropy loss:', tfid_log(0.5, test_data, test_labels, better_preprocessor)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev data processed accuracy: 0.739819004525\n",
      "Dev data processed entropy loss: 0.524777142882\n",
      "Test data processed accuracy: 0.718820861678\n",
      "Test data processed entropy loss: 0.58813838173\n"
     ]
    }
   ],
   "source": [
    "def cv_mnb(param, data, labels, processor=None):\n",
    "\n",
    "    cv= CountVectorizer(analyzer='word', preprocessor=processor)\n",
    "    cvdata=tf.fit_transform(train_data)\n",
    "    mb = MultinomialNB(alpha=param)\n",
    "    mb.fit(cvdata, train_labels)\n",
    "    \n",
    "    cvdev=tf.transform(data)\n",
    "    \n",
    "    # predict classification\n",
    "    predict= mb.predict(cvdev)\n",
    "    post_prob = mb.predict_proba(cvdev)\n",
    "    \n",
    "    accuracy=metrics.f1_score(labels, predict, average='micro')\n",
    "    loss=metrics.log_loss(labels, post_prob)\n",
    "    return [accuracy, loss]\n",
    "\n",
    "# print'dev data accuracy:', cv_mnb(0.5, dev_data, dev_labels)[0]\n",
    "print'Dev data processed accuracy:', cv_mnb(0.5, dev_data, dev_labels, better_preprocessor)[0]\n",
    "\n",
    "# print'Dev entropy loss:', cv_mnb(0.5, dev_data, dev_labels)[1]\n",
    "print'Dev data processed entropy loss:', cv_mnb(0.5, dev_data, dev_labels, better_preprocessor)[1]\n",
    "\n",
    "# print'test data accuracy:', cv_mnb(0.5, test_data, test_labels)[0]\n",
    "print'Test data processed accuracy:', cv_mnb(0.5, test_data, test_labels, better_preprocessor)[0]\n",
    "\n",
    "# print'Test entropy loss:', cv_mnb(0.5, test_data, test_labels)[1]\n",
    "print'Test data processed entropy loss:', cv_mnb(0.5, test_data, test_labels, better_preprocessor)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev data processed accuracy: 0.755656108597\n",
      "Dev data processed entropy loss: 0.537005501462\n",
      "Test data processed accuracy: 0.716553287982\n",
      "Test data processed entropy loss: 0.592988489634\n"
     ]
    }
   ],
   "source": [
    "def tf_mnb(param, data, labels, processor=None):\n",
    "\n",
    "    tf= TfidfVectorizer(analyzer='word', preprocessor=processor)\n",
    "    tfdata=tf.fit_transform(train_data)\n",
    "    mb = MultinomialNB(alpha=param)\n",
    "    mb.fit(tfdata, train_labels)\n",
    "    \n",
    "    tfdev=tf.transform(data)\n",
    "    \n",
    "    # predict classification\n",
    "    predict= mb.predict(tfdev)\n",
    "    post_prob = mb.predict_proba(tfdev)\n",
    "    \n",
    "    accuracy=metrics.f1_score(labels, predict, average='micro')\n",
    "    loss=metrics.log_loss(labels, post_prob)\n",
    "    \n",
    "    return [accuracy, loss]\n",
    "\n",
    "\n",
    "# print'dev data accuracy:', tf_mnb(0.3, dev_data, dev_labels)[0]\n",
    "print'Dev data processed accuracy:', tf_mnb(0.3, dev_data, dev_labels, better_preprocessor)[0]\n",
    "\n",
    "# print'Dev entropy loss:', tf_mnb(0.3, dev_data, dev_labels)[1]\n",
    "print'Dev data processed entropy loss:', tf_mnb(0.3, dev_data, dev_labels, better_preprocessor)[1]\n",
    "\n",
    "# print'test data accuracy:', tf_mnb(0.3, test_data, test_labels)[0]\n",
    "print'Test data processed accuracy:', tf_mnb(0.3, test_data, test_labels, better_preprocessor)[0]\n",
    "\n",
    "# print'Test entropy loss:', tf_mnb(0.3, test_data, test_labels)[1]\n",
    "print'Test data processed entropy loss:', tf_mnb(0.3, test_data, test_labels, better_preprocessor)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Test data #:441\n",
      "False Positives:21%\n",
      "False Negatives:6%\n",
      "\n",
      "Some false positives (tweet, true label, predicted label):\n",
      "('getting sick :| i think ima get the turtle flu lmfaaooo', 0.0, 1)\n",
      "(\"taking the compact carrs for their piggy flu shots. i'm so against the idea, this better not make them sick! #fb #worried #hateshots\", 0.0, 1)\n",
      "(\"rt @ewjjr: difference between bird flu & swine flu: for bird flu you get tweetment. for swine flu you get oinkment. /that's so bad it's good\", 0.0, 1)\n",
      "(\"i want to see obama, his lovely bride and kids get the flu shot first... i don't trust them... talk about fear tactics!  wake up america!\", 0.0, 1)\n",
      "(\"my irrational fear of needles is not helping me get my act together and get a flu shot today... :'(\", 0.0, 1)\n",
      "\n",
      "Some false negatives (tweet, true label, predicted label):\n",
      "('*warning* - @mrporter2012 new beat tape is bird flu sick!!! get at me for info. *warning*', 1.0, 0)\n",
      "('#caringcurrents #h1n1 swine flu alert: adults ages 50 and older getting sicker, dying in higher numbers  http://bit.ly/13bjgf  #eldercare', 1.0, 0)\n",
      "(\"concerned about swine flu, wolfson children's hospital in jacksonville bans visitors under 18 http://bit.ly/yvrdn (via @jaxdotcom)\", 1.0, 0)\n",
      "('#swineflu getting swine flu vaccine top business concern - the associated press http://bit.ly/vbyhq', 1.0, 0)\n",
      "(\"isn't it nice goldman sachs is getting its swine flu shot before my 2 year old?\", 1.0, 0)\n"
     ]
    }
   ],
   "source": [
    "# Take TFidFVectroizer and multinomial bayes as baseline and do error analysis\n",
    "\n",
    "tf= TfidfVectorizer(analyzer='word', preprocessor=better_preprocessor)\n",
    "tfdata=tf.fit_transform(train_data)\n",
    "mb = MultinomialNB(alpha=0.3)\n",
    "mb.fit(tfdata, train_labels)\n",
    "    \n",
    "tfdev=tf.transform(test_data)\n",
    "    \n",
    "# predict classification\n",
    "predictions= list(mb.predict(tfdev))\n",
    "falsePositives = []\n",
    "falseNegatives = []\n",
    "for idx,i in enumerate(test.index.values):\n",
    "    predictedLabel = predictions[idx]\n",
    "    datarow = coloradoData.iloc[i][[\"Tweet_Content\", \"Related_Label\"]]\n",
    "    trueLabel = datarow[\"Related_Label\"]\n",
    "    if int(trueLabel) == 1:\n",
    "        if int(predictedLabel)==0:\n",
    "            falseNegatives.append((datarow[\"Tweet_Content\"], trueLabel, predictedLabel))\n",
    "    elif int(trueLabel) == 0:\n",
    "        if int(predictedLabel) == 1:\n",
    "            falsePositives.append((datarow[\"Tweet_Content\"], trueLabel, predictedLabel))\n",
    "print\"All Test data #:\"+str(len(test_y.index.values))\n",
    "print\"False Positives:\"+str(int(len(falsePositives)*100.0/len(test_y.index.values)))+\"%\"\n",
    "print\"False Negatives:\"+str(int(len(falseNegatives)*100.0/len(test_y.index.values)))+\"%\"\n",
    "print ''\n",
    "print\"Some false positives (tweet, true label, predicted label):\"\n",
    "for row in falsePositives[:5]:\n",
    "    print row\n",
    "print ''\n",
    "print\"Some false negatives (tweet, true label, predicted label):\"\n",
    "for row in falseNegatives[:5]:\n",
    "    print row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
