{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/data_mean_teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNLABELED DATA\n",
    "# combine the encoded unlabeled data (split in many small files) in a single numpy array, which we subsequently write to a single file\n",
    "path = \"data/encoded_sentiment_data/\"\n",
    "unlabeledData = None\n",
    "for i in range(0,103): # Change depending on how much data you want to process\n",
    "    fileName = \"embeddings_w266_\"+str(i)+\".npy\"\n",
    "    data = np.load(path+fileName)\n",
    "    if unlabeledData is None:\n",
    "        unlabeledData = data\n",
    "    else:\n",
    "        unlabeledData = np.concatenate([unlabeledData, data])\n",
    "#     print(data.shape)\n",
    "print(unlabeledData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write unlabeled data in a single file\n",
    "unlabeledDataWithHeaders =np.zeros(unlabeledData.shape[0], dtype = [ ('x', np.float32, (500,)),('y', np.int32, ())])\n",
    "unlabeledDataWithHeaders['x'] = unlabeledData\n",
    "unlabeledDataWithHeaders['y'] = -1\n",
    "print(type(unlabeledDataWithHeaders['x']))\n",
    "\n",
    "finalFileUnlabeled = \"data/data_mean_teacher/embeddings_w266_final.npy\"\n",
    "np.save(finalFileUnlabeled,unlabeledDataWithHeaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that it has been processed correctly\n",
    "path = \"data/data_mean_teacher/embeddings_w266_final.npy\"\n",
    "theData = np.load(path)\n",
    "print(theData['x'].shape)\n",
    "print(theData['y'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELED DATA\n",
    "# split labeled data into three separate files: test, dev, train (80, 10, 10)\n",
    "# data needs to be in special form (see unlabeled processing above, x and y specifically)\n",
    "# write out three files to the right location to be picked up by mean teacher\n",
    "\n",
    "\n",
    "fileName = \"data/encoded_data/embeddings_w266.npy\"\n",
    "encodedData = np.load(fileName)\n",
    "encodedData = pandas.DataFrame(data = encodedData, columns = [\"x_\"+str(i) for i in range(500)])\n",
    "filename = \"data/Labeled_Colorado_Flu_Study_Tweets_AvI_RvN_SvO.csv\"\n",
    "coloradoData = pandas.read_csv(filename, sep=\"\\t\")\n",
    "print(encodedData.shape)\n",
    "allData = pandas.concat([coloradoData, encodedData], axis = 1)\n",
    "print(allData.shape)\n",
    "\n",
    "# get all data with labels present for the column we care about\n",
    "allDataVal = allData.dropna(subset=[\"Related_Label\"])\n",
    "print(allDataVal.shape)\n",
    "\n",
    "# extract X and Y as np arrays, so that we can feed them to tensors. \n",
    "x = allDataVal[[\"x_\"+str(i) for i in range(500)]]\n",
    "y = allDataVal[\"Related_Label\"]\n",
    "print(x.values.shape)\n",
    "print(y.values.shape)\n",
    "\n",
    "# split into train, test, dev (80%,10%,10%). Adjust the split ratio here\n",
    "np.random.seed(42)\n",
    "train_x_df, test_x_df, dev_x_df = np.split(x.sample(frac=1), [int(.8*len(x)), int(.9*len(x))])\n",
    "train_y_df = y[train_x_df.index]\n",
    "test_y_df = y[test_x_df.index]\n",
    "dev_y_df = y[dev_x_df.index]\n",
    "\n",
    "# convert to numpy arrays\n",
    "train_x, test_x, dev_x, train_y, test_y, dev_y = train_x_df.values, test_x_df.values, dev_x_df.values, train_y_df.values, test_y_df.values, dev_y_df.values \n",
    "train_y = train_y.astype(int)\n",
    "dev_y = dev_y.astype(int)\n",
    "test_y = test_y.astype(int)\n",
    "train_x = train_x.astype(\"float32\")\n",
    "test_x = test_x.astype(\"float32\")\n",
    "dev_x = dev_x.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledDataTrain = np.zeros(train_x.shape[0], dtype = [ ('x', np.float32, (500,)),('y', np.int32, ())])\n",
    "labeledDataTest = np.zeros(test_x.shape[0], dtype = [ ('x', np.float32, (500,)),('y', np.int32, ())])\n",
    "labeledDataDev = np.zeros(dev_x.shape[0], dtype = [ ('x', np.float32, (500,)),('y', np.int32, ())])\n",
    "labeledDataTrain['x'] = train_x\n",
    "labeledDataTrain['y'] = train_y\n",
    "labeledDataTest['x'] = test_x\n",
    "labeledDataTest['y'] = test_y\n",
    "labeledDataDev['x'] = dev_x\n",
    "labeledDataDev['y'] = dev_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the actual data\n",
    "finalFileLabeledTrain = \"data/data_mean_teacher/encoded_labeled_train_data.npy\"\n",
    "np.save(finalFileLabeledTrain,labeledDataTrain)\n",
    "\n",
    "finalFileLabeledTest = \"data/data_mean_teacher/encoded_labeled_test_data.npy\"\n",
    "np.save(finalFileLabeledTest,labeledDataTest)\n",
    "\n",
    "finalFileLabeledDev = \"data/data_mean_teacher/encoded_labeled_dev_data.npy\"\n",
    "np.save(finalFileLabeledDev,labeledDataDev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
